import requests
from bs4 import BeautifulSoup
from queue import Queue
from threading import Thread
from urllib.parse import urlparse, urljoin
from time import sleep

class VulnerabilityScanner:
    def __init__(self, target_urls, num_threads=5, delay=1, user_agent=None):
        self.target_urls = target_urls
        self.num_threads = num_threads
        self.queue = Queue()
        self.results = []
        self.delay = delay
        self.user_agent = user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
        self.session = requests.Session()
        self.discovered_urls = set()

    def validate_url(self, url):
        parsed_url = urlparse(url)
        if parsed_url.scheme not in ['http', 'https']:
            return None
        return urljoin(url, parsed_url.path)

    def crawl_and_parse(self, url):
        headers = {"User-Agent": self.user_agent}
        try:
            response = self.session.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                for form in soup.find_all('form'):
                    action = form.get('action')
                    if action:
                        full_url = urljoin(url, action)
                        self.queue.put(('form', full_url))
                for link in soup.find_all('a', href=True):
                    link_url = urljoin(url, link.get('href'))
                    self.queue.put(('link', link_url))
        except requests.RequestException as e:
            print(f"Error fetching {url}: {e}")

    def generate_payloads(self):
        payloads = [
            '<script>alert("XSS");</script>',
            "' OR '1'='1",
            '<img src=x onerror=alert("XSS")>',
            # Add more payloads here
        ]
        for payload in payloads:
            self.queue.put(('xss', payload))
            self.queue.put(('sql', payload))

    def test_xss(self, url, payload):
        response = self.session.get(url)
        if payload in response.text:
            self.results.append({'url': url, 'vulnerability': 'XSS', 'payload': payload})

    def test_sql_injection(self, url, payload):
        response = self.session.get(url)
        if 'error' in response.text:
            self.results.append({'url': url, 'vulnerability': 'SQL Injection', 'payload': payload})

    def process_queue(self):
        while not self.queue.empty():
            item = self.queue.get()
            if len(item) >= 3 and item[0] == 'xss':
                self.test_xss(item[1], item[2])
            elif len(item) >= 3 and item[0] == 'sql':
                self.test_sql_injection(item[1], item[2])
            elif len(item) >= 2 and (item[0] == 'form' or item[0] == 'link'):
                if item[1] not in self.discovered_urls:
                    self.crawl_and_parse(item[1])
                    self.discovered_urls.add(item[1])
            sleep(self.delay)  # Throttle requests

    def run_scan(self):
        for url in self.target_urls:
            validated_url = self.validate_url(url)
            if validated_url:
                self.queue.put(('xss', validated_url))
                self.queue.put(('sql', validated_url))
                self.discovered_urls.add(validated_url)
        self.generate_payloads()

        threads = []
        for _ in range(self.num_threads):
            thread = Thread(target=self.process_queue)
            thread.start()
            threads.append(thread)

        for thread in threads:
            thread.join()

        self.generate_report()

    def generate_report(self):
        report = "Scan Report:\n"
        for result in self.results:
            report += f"URL: {result['url']}\n"
            report += f"Vulnerability: {result['vulnerability']}\n"
            report += f"Payload: {result['payload']}\n\n"

        with open("output.txt", "w") as file:
            file.write(report)

if __name__ == '__main__':
    target_urls = ['target url']  # Update with your target URLs
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    scanner = VulnerabilityScanner(target_urls, delay=2, user_agent=user_agent)
    scanner.run_scan()
    print("Scan completed. Results written to output.txt")
